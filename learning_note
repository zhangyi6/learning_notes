set()可以记录没有重复的数据集

--------------2018.5.2-----------------
i've learned about first chapter of the course called 'data_analysis' 
from Udacity, done some practice of this course, and generally know 
the process of data analysis, that is:
1. observe the frame of the data set, and come up with questions about
  the data, find the abnormal nouns

2. then correct the abnormal nouns

3. make the data visible (use matplotlib.pyplot)

goal:
finish the chapter about 'How to use Numpy and Pandas to analysis ...
1-dimensional data'

--------------Numpy & Pandas------------
1. np.array([])
   pd.Series({})

2. Numpy: mean(), std(), max(), min(), data[1:3]-->operate raw data
   '+='-->operate raw data, 'a = a + xx'-->create a new array

   Pandas: + describle(), loc[]-->position index, iloc[]-->key index
          argmax(), dropna()-->remove NaN value, fillna('0')-->
          replace NaN as '0',
          special using : s1.add(s2, fill_value=0)-->show all value
          without NaN
-------------Numpy & Pandas(2-dimension)------
1. i could use DataFrame to deal with csv file

2. df.applymap(Func)-->for all value
   df.apply(Func) -->for all column
   DataFrame add Series equal to 'column of DataFrame' add 
   'each value which match the column-index'

3. df.groupby(['key1', 'key2'], as_index=False) -->key1 and key2
   will not be use to get it's value ,so use 'as_index=False' can 
   fix this problem

4. df1.merge(df2, on=['key1','key2'], how='left' or 'inner' or 'right')
   -->'on=' is the keyword which refered to merge
   -->'how=' is the way to merge

------------Descriptive Statistic--------------
1. 贝塞尔校正：样本估计总体的标准差时，分子n应该是n-1,因为总体的
   标准差应该比样本的大；

2. 直方图的组距牺牲了一部分信息，但如果组距无限小，则没有啦形状

3. 任何分布都可以改写成正态分布，x-axis为z=(x-μ)/σ-->改写成
   距离中心z=0有多少个标准偏差

4. 样本的异常值的判断：Outlier < Q1 - 1.5(IQR) or > Q3 + 1.5(IQR)
   其中IQR等于Q3，Q1的均值

5. 中心极限定理：反映了样本的标准偏差和总体的标准偏差之间的关系
   SE = σ/n^(1/2)
-----------Formally starting the ML course-------
General learning about ML
1. Logistic regresion & SVM & Neutrul network & kernal function
   --> classify problem solving method
   Logistic regression divides the sample by linear
   and the other method by curve

2. SVM has some parameters:
   * kernal: linear, poly, rbf
   * degree: int, decide the polynomial's hightest degree 
   * gramma: need to learn in next course 
   * C: need to learn in next course 

3. use sklearn to test the performance of model
   * firstly, we should divide the training data to two parts
     "from sklearn.cross_validation import train_test_split"
     "X.train, X.test, y.train, y.test = train_test_split(X, y, test_size)"
   * then estimate the model
     - accuracy_score
     - recall
     - precision
     - F1 score
     - Fβ
     - ROC: perfect:1, good:0.8, random: 0.5
     - mean absolute error:
       from sklean.metrics import mean_absolute_error
       from sklean.linear_model import LinearRegression
       classifier = LinearRegression()
       classifier.fit(X, y)
       guesses = classifier.predict(X)
       error = mean_absolute_error(y, guesses)
     - mean squared error
       just replace mean_absolute_error by mean_squared_error
     - R2 score
       1 - (linear regression) / (mean line)
       if R2--> 1 : show that the model works well
          R2--> 0 : to be contrary
          
          from sklean.metrics import r2_score
          r2_score(y_true, y_pred  
---------------model selection--------------------
1. the most important thing is the k-fold cross validation and then grid search
   'k-fold cross validation'-->divide the data into k piece of sample,
   take 1 to test and the left to train, every time we shuffle the data, 
   so that estimate any kind of bias
   code:
   from sklearn.model_selection import kFold
   kf = kFold(12, 3, shuffle=True)
   for train_indices, test_indices in kf:
       print...
   grid search-->
   from sklearn.model_selection import GridSearchCV
   grid_obj = GridSearchCV(estimator=clf, 
                          params_grid=parameter, cv=kFold, scoring=scorer)
   grid_fit = grid_obj.fit(X_train, y_train)
   best_clf = grid_fit.best_estimator_
   best_clf.fit(X_train, y_train)

2. learn how to search the parameter of sklearn

--------------decision tree-----------------------
1. Entropy = -m/(m+n)*log(m/(m+n)) - n/(m+n)*log(n/(m+n))

2. information gain = Entropy(parents) - 0.5(Entropy(child1) + Entropy(child2))
   the task is to maximum the information gain

3. random forest : select the node randomly, and all predict y

4. hyperparameters of decision tree:
   * max_depth
   * min_sample_leaf
   * min_sample_split --> the minimun number of sample spliting the inner node 
   * max_feature

--------------the project of decision tree--------
1. too hard to clean data, but there are still some valuable things i've learn
   first, string dealing method:
   * strip() --> delete head and tail position's string(often space)
   * replace(x1, x2) --> replace x1 to x2 (x1, x2 are both string)
   * str.maketrans and translate
   * re.sub(patter, repl, string, count)

2. one thing i should keep digging is regulization, i want to find out 
   the meaning of 'r', 'b', 'f' etc

--------------SVM && Bagging and Boosting---------
1. classification error + margin error = ERROR
2. C hyperparameter: if C is large, then classification is good, but 
                     margin is small
                     if C is small, then classification is bad, but 
                     margin is large
3. kernel: 'linear', 'poly', 'rbf'

4. AdaBoost: the precess of achiving the AdaBoost
             * get the best shoot to divide data into two different part
             * change the weight of correct and incorrect data to the same
             * find out the other simple classifier and change the weight
             * repeat n times
             * calculate each classifier's weight(equel In(correct/incorret))
             ** get all the indivitual parts and vote by the weight of each part
             ** positive shows that it is positive

---------------neural network--------------------
The tons of method to optimize neural network
1. early-stop: according to the model complixity graph, we should pick
   the smallest epochs which make test-error lowest to avoid overfitting

2. Regulization: add (L1, L2 regulization method) to error function to 
   avoid overfitting
   L1: prefer to get a sparse vector which make some unimportance feature 
   zero
   L2: prefer to get a weight vetor with small value for every feature

3. Use dropout layer against overfitting

4. Use other excitation function rather than sigmoid function, for example:
   tanh(), relu

5. Batch and random gradiant descent:
   random select some small batch of data to train the model each epochs

6. Learning rate decrease:
   if steep, long step
   if plain, small step
   in case of missing the lowest valley

7. randomly restart: starting from different situation to find the overall
   lowest valley

8. momentum: when take a step, take this: step(n) + beta*step(n-1) + 
   beta^2 * step(n-2) ...
   beside, beta is called momentum

----------------deep learning-------------
1. this is a challenging task to do, so give me one more day,haha```